# ğŸ§  Deep Research Agent â€” MCP Orchestrator

> *A general-purpose deep research agent built on the MCP-Agent architecture.*

---

## ğŸ— Overview

The **Deep Research Agent** is an open-source, production-ready implementation of a **multi-step reasoning and research system** powered by **MCP-Agent** â€” a modular framework for connecting large language models (LLMs) to tool servers and structured data via the **Model Context Protocol (MCP)**.

It combines deterministic orchestration, context-aware planning, and dynamic workflow execution to perform **complex research tasks** autonomously â€” from academic investigations to financial and scientific analysis.

---

## ğŸ¯ Objective

To build a **general-purpose deep research agent** that can:
- Perform complex, multi-step reasoning and tool-using tasks  
- Dynamically plan, execute, and refine research workflows  
- Integrate with multiple MCP servers and tools  
- Manage external context, memory, and token budgets efficiently  
- Verify and reflect on plans deterministically before execution  

---

## âš™ï¸ Architecture

### 1. Planning Layer
Breaks down the userâ€™s objective into **structured subtasks** using a high-reasoning LLM.  
Defines dependencies, tool usage, and memory needs upfront.

### 2. Execution Layer
Executes the subtasks sequentially or in parallel.  
Each step gathers context, stores memory, and passes relevant knowledge forward.

### 3. Verification Layer
Validates the plan **before** running it:
- Checks MCP server and agent availability  
- Verifies dependency graph consistency  
- Prevents hallucinated calls or undefined tools  

### 4. Policy Engine
Controls workflow decisions:
- **Continue Executing** â€” proceed normally  
- **Trigger Replanning** â€” replan based on new context  
- **Emergency Stop** â€” halt due to repeated failure  
- **Force Completion** â€” end gracefully on timeout or budget limit  

---

## ğŸ” Key Features

| Feature | Description |
|:--------|:-------------|
| **Deterministic Verification** | Code-based validation of plan structure, dependencies, and agents |
| **External Memory** | Knowledge banks for persistent, efficient context recall |
| **Dynamic Planning** | LLM builds and updates plans as tasks progress |
| **Context Graph** | Task dependency map defines what memory to propagate |
| **Budget Management** | Tracks tokens, cost, and latency through all steps |
| **Beast Mode** | Graceful fallback output when limits are reached |
| **XML-Structured Prompts** | Prompts built programmatically for clarity and modularity |

---

## ğŸ”„ Evolution

### ğŸ§± Take 1 â€” Orchestrator
- Fixed plan created upfront  
- Worked well for simple workflows  
- Failed in dynamic reasoning and token efficiency  

### ğŸ”„ Take 2 â€” Adaptive Workflow
- Added external memory, token budgets, and dynamic subagents  
- Over-engineered: slower, more complex, less reliable  

### ğŸš€ Take 3 â€” Deep Orchestrator
- Returned to simpler orchestration loop with deterministic verification  
- Balanced performance, reliability, and reasoning depth  

> **Core insight:**  
> *Simplicity beats complexity â€” verified loops outperform dynamic chaos.*

---

## ğŸ§© Core Loop

```text
1ï¸âƒ£  Receive user objective  
2ï¸âƒ£  Generate initial plan (with substeps + dependencies)  
3ï¸âƒ£  Verify plan deterministically  
4ï¸âƒ£  Execute tasks (sequentially/parallel)  
5ï¸âƒ£  Aggregate context + update memory  
6ï¸âƒ£  Verify outcome â†’ if incomplete, replan  
7ï¸âƒ£  Synthesize final result


---

ğŸ’¡ Key Learnings

1. Simple architecture wins â€” A minimal deterministic loop performs better than over-complex dynamic systems.


2. MCP is all you need â€” Any research or analysis task can be composed entirely from MCP tool servers.


3. Prompt structure matters â€” Well-formed, sectioned prompts with XML or structured formatting dramatically improve reasoning reliability.


4. Hybrid reasoning loop â€” Code + LLM synergy (deterministic checks + generative reasoning) leads to stable, scalable behavior.




---

ğŸ§  Future Directions

Remote Execution via MCP â€” Expose orchestration as callable MCP servers

Intelligent Tool Selection â€” Smart subagent creation and tool filtering

Memory as MCP Resources â€” Represent knowledge stores as URI-accessible MCP data

Dynamic Model Switching â€” Use smaller LLMs for tool calls, larger for reasoning



---

ğŸ§­ Repository

Source code and examples available at:
ğŸ‘‰ Deep Orchestrator Workflow â€“ MCP-Agent


---

ğŸ“˜ Example Use Case

Finance Research Agent

Connects to an MCP server for financial datasets

Plans a multi-step query (trend analysis â†’ data retrieval â†’ synthesis)

Verifies plan, executes, and generates an analytical report

Replans if the objective remains unsatisfied



---

ğŸ§© Tech Stack

Layer	Technology

Framework	MCP-Agent
Orchestration	Deep Orchestrator Workflow
Model	Any MCP-compatible LLM (Claude, GPT, etc.)
Memory	External Knowledge Store / MCP Resource
Verification	Deterministic plan validator (Python-based)
Execution	MCP Tool Calls / Subagent chaining
